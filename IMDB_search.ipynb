{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "FPyAo0GJzkGl",
    "31YRwn9Fzrm8"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setting Up"
   ],
   "metadata": {
    "id": "BQBWsgrMza4X"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sFHzO2Zr9Wm2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c37dcd5b-df89-4799-c733-93fcc5d954a6"
   },
   "source": [
    "!pip install scikit-learn\n",
    "!pip install nltk"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import json"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pb9ff1e-9lls",
    "outputId": "5b405b3c-3cf9-401c-92ea-973a7cf2603c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading data from file"
   ],
   "metadata": {
    "id": "FPyAo0GJzkGl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Movie:\n",
    "    def __init__(self, _id, title, plot, directors, writers, actors):\n",
    "        self.imdb_id = _id\n",
    "        self.title = title.split('. ')[-1]\n",
    "        self.plot = plot\n",
    "        self.directors = directors\n",
    "        self.writers = writers\n",
    "        self.actors = actors\n",
    "    def to_process(self):\n",
    "        actors_list = []\n",
    "        for actor in self.actors:\n",
    "            actors_list.append(actor['name'])\n",
    "        result = self.title + ' ' + self.plot + ' ' + ' '.join(self.directors) + ' ' + ' '.join(self.writers) + ' ' + ' '.join(actors_list)\n",
    "        return result\n",
    "    def __str__(self):\n",
    "        return f'{self.imdb_id} - \"{self.title}\"'"
   ],
   "metadata": {
    "id": "RgY_GkIS-yPW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def as_movie(dct):\n",
    "  return Movie(dct['imdb_id'], dct['title'], dct['plot'],\n",
    "               dct['directors'], dct['writers'], dct['actors'],)"
   ],
   "metadata": {
    "id": "g3TWIbUQ9ouP"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "movies = []\n",
    "with open('./imdb_search/imdb-movies.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            movie_data = json.loads(line)\n",
    "            movie = as_movie(movie_data)\n",
    "            movies.append(movie)\n",
    "        except json.JSONDecodeError as e:\n",
    "            continue"
   ],
   "metadata": {
    "id": "348IIx6pQ2zM"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "id": "31YRwn9Fzrm8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    # case folding\n",
    "    text = text.lower()\n",
    "\n",
    "    # stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text_tokenized = word_tokenize(text)\n",
    "    text_tokenized = [word for word in text_tokenized if not word in stop_words]\n",
    "\n",
    "    # stemming\n",
    "    ps = PorterStemmer()\n",
    "    text_tokenized = [ps.stem(word) for word in text_tokenized]\n",
    "\n",
    "    text = ' '.join(text_tokenized)\n",
    "    return text"
   ],
   "metadata": {
    "id": "HmS7ju4TASnz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Information Retrieval\n"
   ],
   "metadata": {
    "id": "XiwRuQ2azwL0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def documents_to_cosine_similarities(documents, search_query):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    query_tfidf_vector = tfidf_vectorizer.transform([search_query])\n",
    "    cosine_similarities_tfidf = cosine_similarity(query_tfidf_vector, tfidf_matrix)\n",
    "    return cosine_similarities_tfidf\n"
   ],
   "metadata": {
    "id": "Arh3QkDZOzdm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IR System"
   ],
   "metadata": {
    "id": "rhCaxSLl0Dc5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query = input()\n",
    "processed_movies = [preprocess_text(str(movie.to_process())) for movie in movies]\n",
    "query = preprocess_text(query)\n",
    "cosine_movies = documents_to_cosine_similarities(processed_movies, query)\n",
    "print(movies[cosine_movies.flatten().argmax()])\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmhpafNFOnnu",
    "outputId": "47b47b4e-0782-443c-f8b2-b6af7829c2f6"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
